# 实时语音识别会议纪要系统

## 📋 项目简介
基于 FunASR 与 Web 技术的实时语音识别系统，支持在线实时转写与离线说话人分离，可自动生成结构化会议纪要。

## ✨ 核心特性
- 🎤 **实时语音转写**：基于 SenseVoiceSmall 模型，支持中英文混合识别
- 👥 **说话人分离**：录音结束后自动区分不同发言人并标注
- ⏱️ **时间戳标注**：每句话均附带起止时间，便于回溯与定位
- 📄 **结构化输出**：生成带说话人标签和时间戳的 JSON 格式会议记录
- 💾 **本地自动保存**：完整录音文件及处理结果按会话自动归档
- 🌐 **Web 交互界面**：简洁直观的前端操作，无需安装客户端

## 🛠️ 技术栈
| 模块         | 技术/模型                          |
|--------------|------------------------------------|
| **后端框架** | FastAPI + WebSocket                |
| **前端技术** | HTML + JavaScript (Web Audio API)  |
| **语音识别** | SenseVoiceSmall (实时)             |
| **语音活动检测** | fsmn-vad                         |
| **离线处理** | seaco-paraformer-large + campplus  |
| **音频处理** | WebRTC, PCM 编码, 16kHz 重采样     |

## 🚀 快速开始

### 1. 环境准备
```bash
# Python 3.8+
python --version

# 克隆项目
git clone <项目地址>
cd <项目目录>

# 安装依赖
pip install -r requirements.txt
```

### 2. 启动服务
```bash
# 启动后端服务（默认端口 27000）
python app.py --host 0.0.0.0 --port 27000

# 可选参数
# --host  绑定地址 (默认: 0.0.0.0)
# --port  服务端口 (默认: 27000)
```

### 3. 使用系统
1. **打开前端**：浏览器访问 `index.html`（支持 Chrome/Edge 等现代浏览器）
2. **开始录音**：点击“开始录制”按钮，授予麦克风权限
3. **实时转写**：系统实时显示识别文字，带时间戳
4. **结束处理**：点击“停止录制”，系统自动进行说话人分离
5. **查看结果**：页面显示带说话人标签的完整会议纪要

## 📁 输出文件结构
```
output/YYYYMMDD_HHMMSS/
├── session_full.wav          # 完整录音（WAV格式）
├── stream_output.json        # 结构化会议纪要（JSON）
└── debug_segments_raw.json   # 原始识别片段（调试用）
```

### 📊 JSON 输出示例
```json
{
  "audio_full": {
    "path": "output/20250101_120000/session_full.wav",
    "sample_rate": 16000,
    "channels": 1
  },
  "segments": [
    {
      "spk": "0",
      "text": "大家好，我们开始今天的会议。",
      "start_ms": 0,
      "end_ms": 3200
    },
    {
      "spk": "1",
      "text": "我同意这个提议。",
      "start_ms": 4500,
      "end_ms": 6200
    }
  ]
}
```

## 🔌 API 接口
| 端点 | 方法 | 说明 |
|------|------|------|
| `ws://localhost:27000/ws/transcribe` | WebSocket | 实时语音转写（支持 `lang=auto` 参数） |
| `http://localhost:27000/health` | GET | 服务健康检查 |

## ⚙️ 关键配置
### 实时识别参数（`app.py`）
```python
RATE = 16000                    # 音频采样率
RT_VAD_CHUNK_MS = 300           # VAD 分块大小（毫秒）
RT_MAX_END_SILENCE_MS = 500     # 最大结束静音时间
```

### 离线处理参数
```python
MERGE_CONTINUOUS_SPK = True     # 合并同一说话人连续片段
MERGE_GAP_MS = 300              # 合并间隔阈值（毫秒）
```

## 🎯 前端功能说明
### 操作按钮
- **开始/停止录制**：控制录音流程
- **复制结果**：复制转写文本到剪贴板
- **下载文件**：保存转写结果为 TXT 文件（支持现代浏览器的“另存为”对话框）

### 显示区域
- **实时转写结果**：逐句显示，带时间戳
- **会议纪要**：录音结束后生成的带说话人标签的完整文本

## 🔧 故障排除
| 问题现象 | 可能原因 | 解决方案 |
|----------|----------|----------|
| 模型下载失败 | 网络问题 | 检查网络连接，确保可访问 ModelScope |
| GPU 内存不足 | 显存不够 | 减小批处理大小，或在 CPU 模式下运行 |
| WebSocket 连接失败 | 端口占用/防火墙 | 检查端口 27000 是否可用，关闭防火墙限制 |
| 麦克风无法使用 | 浏览器权限/硬件问题 | 检查浏览器麦克风权限，确认麦克风正常工作 |
| 识别延迟较高 | 网络或性能瓶颈 | 确保使用 GPU，检查网络稳定性 |

## 📈 性能建议
- **硬件**：使用 NVIDIA GPU 可大幅提升处理速度
- **环境**：在安静环境下录音，识别准确率更高
- **网络**：稳定的网络连接有助于实时传输
- **说话方式**：避免多人同时发言，系统支持但不推荐重叠语音

## ⚠️ 注意事项
1. **首次运行**：需要下载约 5GB 模型文件，请确保磁盘空间充足
2. **隐私安全**：录音文件保存在本地，注意数据保密
3. **实时延迟**：系统有 300-500ms 的处理延迟，属正常范围
4. **说话人识别**：仅离线阶段进行，非实时功能
5. **浏览器支持**：需支持 WebSocket 和 Web Audio API

## 📋 待开发功能
- [ ] 实时说话人分离（在线阶段）
- [ ] AI 自动会议摘要生成
- [ ] 多语言实时翻译
- [ ] 前端实时字幕显示优化
- [ ] 导出格式扩展（Word、PDF、SRT 字幕等）

## 📞 技术支持
如遇问题，请：
1. 查看控制台错误日志
2. 检查 `output/` 目录下的调试文件
3. 提交 Issue 或联系项目维护者

---

**版本**：1.0.0 | **最后更新**：2024年1月 | **适用场景**：会议记录、访谈转录、课堂笔记等语音转文字需求